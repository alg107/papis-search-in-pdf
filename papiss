#!/usr/bin/env python3
import papis.api as p
import os.path
from pdfminer.high_level import extract_text
from fuzzysearch import find_near_matches
from sys import argv

lib = 'papers'

def gen_texts(lib='papers'):
    # At some point use hashes to check if text needs updating
    # Or at least check for existing text.txt
    docs = p.get_all_documents_in_lib(lib)
    for doc in docs:
        fname = doc.get_files()[0]
        folder = doc.get_main_folder()
        if not os.path.isfile(f'{folder}/text.txt'):
            with open(f'{folder}/text.txt', 'w') as f:
                extracted = extract_text(fname)
                print(extracted)
                f.write(extracted)

def doc_matches(sstr, doc):
    folder = doc.get_main_folder()
    doctext = ''
    with open(f'{folder}/text.txt', 'r') as f:
        doctext = f.read()
    matches = find_near_matches(sstr, doctext, max_l_dist=1)
    matches_n = len(matches)
    if matches_n > 0:
        return True
    else:
        return False


def search(sstr, lib=lib):
    docs = p.get_all_documents_in_lib(lib)
    filtered = list(filter(lambda x: doc_matches(sstr,x), docs))
    picked = p.pick_doc(filtered)[0]
    p.open_file(picked.get_files()[0])
    return picked
    

if __name__ == "__main__":
    if len(argv) == 1:
        picked = p.pick_doc(p.get_all_documents_in_lib(lib))
        p.open_file(picked.get_files()[0])
    gen_texts()
    search(argv[1])
